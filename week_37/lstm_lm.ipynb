{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import math\n",
    "import functools as ft\n",
    "import operator\n",
    "from bpemb import BPEmb\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use GPU if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_reproducibility(seed=42):\n",
    "    # Sets seed manually for both CPU and CUDA\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # System based\n",
    "    #random.seed(seed)\n",
    "    #np.random.seed(seed)\n",
    "\n",
    "enforce_reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dir_path = os.getcwd()[:-1]+'6'\n",
    "train_df = pd.read_csv(dir_path+'/train_data.csv')\n",
    "val_df = pd.read_csv(dir_path+'/train_data.csv')\n",
    "\n",
    "# divide data set\n",
    "train_arab = train_df[train_df['language'] == 'arabic']\n",
    "train_indo = train_df[train_df['language'] == 'indonesian']\n",
    "train_beng = train_df[train_df['language'] == 'bengali']\n",
    "\n",
    "val_arab = val_df[val_df['language'] == 'arabic']\n",
    "val_indo = val_df[val_df['language'] == 'indonesian']\n",
    "val_beng = val_df[val_df['language'] == 'bengali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 50\n",
    "\n",
    "bpemb_bn = BPEmb(lang=\"bn\", dim=embedding_dim, vs=vocab_size) # Bengali\n",
    "bpemb_ar = BPEmb(lang=\"ar\", dim=embedding_dim, vs=vocab_size) # Arabic\n",
    "bpemb_id = BPEmb(lang=\"id\", dim=embedding_dim, vs=vocab_size) # Indonesian\n",
    "\n",
    "embeddings_ar = bpemb_ar.emb.vectors\n",
    "embeddings_bn = bpemb_bn.emb.vectors\n",
    "embeddings_id = bpemb_id.emb.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, seq_len, num_batches, idx):\n",
    "    \"\"\"\n",
    "    given the index of the first batch of tokens in the batch returns the \n",
    "    corresponding batch of sequences.\n",
    "    \n",
    "    data: in [batch size, num_batches] format\n",
    "    seq_len: length of sequence\n",
    "    idx: index\n",
    "\n",
    "    returns: input and targets of the LSTM  \n",
    "    \"\"\"    \n",
    "    src = data[:, idx:idx+seq_len]        # \n",
    "    target = data[:, idx+1:idx+seq_len+1] # next words       \n",
    "    return src, target\n",
    "\n",
    "# define dataloader \n",
    "def get_data(dataset: list, vocab, batch_size):\n",
    "    \"\"\"\n",
    "    dataset: pandas series\n",
    "    vocab: bpemb entity\n",
    "    batch_size: size of batch\n",
    "    \"\"\"\n",
    "    encoded = vocab.encode_ids_with_eos(dataset.values)\n",
    "    flat = ft.reduce(operator.iconcat, encoded, [])\n",
    "    data = torch.tensor(flat)\n",
    "    num_batches = data.shape[0] // batch_size\n",
    "    data = data[:num_batches * batch_size] # remove modulus (leftovers)\n",
    "    data = data.view(batch_size, num_batches) \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, lstm_layers: int, \n",
    "                 dropout_rate: float, tie_weights: bool, vocab):\n",
    "                \n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab.vectors.shape[0]\n",
    "        self.embedding_dim = vocab.vectors.shape[1]\n",
    "        self.num_layers = lstm_layers\n",
    "\n",
    "        self.model = nn.ModuleDict({\n",
    "            'embeddings': nn.Embedding.from_pretrained(torch.tensor(vocab.vectors)),\n",
    "            'lstm': nn.LSTM(\n",
    "                self.embedding_dim,\n",
    "                hidden_dim,\n",
    "                lstm_layers,\n",
    "                batch_first=True,\n",
    "                dropout=dropout_rate,\n",
    "                bidirectional=False),\n",
    "            'fc': nn.Linear(hidden_dim, vocab_size)\n",
    "        })\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        if tie_weights:\n",
    "            assert embedding_dim == hidden_dim, 'cannot tie, check dims'\n",
    "            self.embedding.weight = self.fc.weight\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        all_params = list(self.model['lstm'].named_parameters()) + \\\n",
    "                     list(self.model['fc'].named_parameters())\n",
    "        for n,p in all_params:\n",
    "            if 'weight' in n:\n",
    "                nn.init.xavier_normal_(p)\n",
    "            elif 'bias' in n:\n",
    "                nn.init.zeros_(p)\n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        return hidden, cell\n",
    "    \n",
    "    def detach_hidden(self, hidden):\n",
    "        hidden, cell = hidden\n",
    "        hidden = hidden.detach()\n",
    "        cell = cell.detach()\n",
    "        return hidden, cell\n",
    "\n",
    "    def forward(self, src, hidden):\n",
    "        embeds = self.model['embeddings'](src)\n",
    "        lstm_out, hidden = self.model['lstm'](embeds)      \n",
    "        fc_in = self.dropout(lstm_out) \n",
    "        logits = self.model['fc'](fc_in)\n",
    "\n",
    "        return logits, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "def train(model, data, optimizer, criterion, batch_size, seq_len, clip, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    model.train() # training mode - dropout not disabled\n",
    "    # drop all batches that are not a multiple of seq_len\n",
    "    num_batches = data.shape[-1]\n",
    "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
    "    num_batches = data.shape[-1]\n",
    "\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "    \n",
    "    # The last batch can't be a src\n",
    "    for idx in tqdm(range(0, num_batches - 1, seq_len), desc='Training: ',leave=False):  \n",
    "        optimizer.zero_grad()\n",
    "        hidden = model.detach_hidden(hidden)\n",
    "\n",
    "        src, target = get_batch(data, seq_len, num_batches, idx)\n",
    "        src, target = src.to(device), target.to(device)\n",
    "        batch_size = src.shape[0]\n",
    "        prediction, hidden = model(src, hidden)               \n",
    "        prediction = prediction.reshape(batch_size * seq_len, -1)   \n",
    "        target = target.reshape(-1)\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * seq_len\n",
    "    return epoch_loss / num_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, criterion, batch_size, seq_len, device):\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    \n",
    "    num_batches = data.shape[-1]\n",
    "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
    "    num_batches = data.shape[-1]\n",
    "\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "\n",
    "    with torch.no_grad(): # we no longer need to backprop or keep track of gradients.\n",
    "        for idx in range(0, num_batches - 1, seq_len):\n",
    "            hidden = model.detach_hidden(hidden)\n",
    "            src, target = get_batch(data, seq_len, num_batches, idx)\n",
    "            src, target = src.to(device), target.to(device)\n",
    "            batch_size= src.shape[0]\n",
    "\n",
    "            prediction, hidden = model(src, hidden)\n",
    "            prediction = prediction.reshape(batch_size * seq_len, -1)\n",
    "            target = target.reshape(-1)\n",
    "\n",
    "            loss = criterion(prediction, target)\n",
    "            eval_loss += loss.item() * seq_len\n",
    "    return eval_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "num_layers = 2\n",
    "dropout_rate = 0.1\n",
    "hidden_dim = 128\n",
    "tie_weights = True if embedding_dim == hidden_dim else False\n",
    "\n",
    "# Training\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "seq_len = 10\n",
    "clip = 0.25\n",
    "\n",
    "saved = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tTrain Perplexity: 689.738\n",
      "\tValid Perplexity: 345.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "\tTrain Perplexity: 215.796\n",
      "\tValid Perplexity: 157.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "\tTrain Perplexity: 138.715\n",
      "\tValid Perplexity: 109.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "\tTrain Perplexity: 100.010\n",
      "\tValid Perplexity: 81.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "\tTrain Perplexity: 78.384\n",
      "\tValid Perplexity: 65.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "\tTrain Perplexity: 65.424\n",
      "\tValid Perplexity: 55.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "\tTrain Perplexity: 56.169\n",
      "\tValid Perplexity: 47.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "\tTrain Perplexity: 49.238\n",
      "\tValid Perplexity: 42.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "\tTrain Perplexity: 43.973\n",
      "\tValid Perplexity: 37.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain Perplexity: 39.766\n",
      "\tValid Perplexity: 34.174\n",
      "\t Final train Perplexity: 39.766\n"
     ]
    }
   ],
   "source": [
    "ln = 'arab'\n",
    "doc = 'question_text'\n",
    "vocab = bpemb_ar\n",
    "\n",
    "train_data = get_data(train_arab[doc], vocab, batch_size)\n",
    "val_data = get_data(val_arab[doc], vocab, batch_size)\n",
    "\n",
    "model = LSTM(hidden_dim, num_layers, dropout_rate, tie_weights, vocab).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# reduce learning rate as we go along \n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0) \n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_loss = train(model, train_data, optimizer, criterion, \n",
    "                batch_size, seq_len, clip, device)\n",
    "    valid_loss = evaluate(model, val_data, criterion, batch_size, \n",
    "                seq_len, device)\n",
    "    \n",
    "    lr_scheduler.step(valid_loss)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        name = 'best-val-'+ln+'-'+doc+'.pt'\n",
    "        torch.save(model.state_dict(), name)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    print(f'\\tTrain Perplexity: {math.exp(train_loss):.3f}')\n",
    "    print(f'\\tValid Perplexity: {math.exp(valid_loss):.3f}')\n",
    "\n",
    "valid_loss = evaluate(model, train_data, criterion, batch_size, \n",
    "                seq_len, device)\n",
    "print(f'\\tFinal train Perplexity: {math.exp(valid_loss):.3f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Lanuage: arab\n",
      "Data: question_text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tTrain Perplexity: 729.760\n",
      "\tValid Perplexity: 447.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "\tTrain Perplexity: 229.833\n",
      "\tValid Perplexity: 157.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "\tTrain Perplexity: 135.634\n",
      "\tValid Perplexity: 106.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "\tTrain Perplexity: 96.356\n",
      "\tValid Perplexity: 77.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "\tTrain Perplexity: 74.539\n",
      "\tValid Perplexity: 61.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "\tTrain Perplexity: 62.014\n",
      "\tValid Perplexity: 52.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "\tTrain Perplexity: 53.508\n",
      "\tValid Perplexity: 45.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "\tTrain Perplexity: 47.203\n",
      "\tValid Perplexity: 40.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "\tTrain Perplexity: 42.238\n",
      "\tValid Perplexity: 36.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain Perplexity: 38.171\n",
      "\tValid Perplexity: 32.662\n",
      "\tFinal train Perplexity: 32.662\n",
      "Data: document_plaintext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tTrain Perplexity: 763.998\n",
      "\tValid Perplexity: 429.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "\tTrain Perplexity: 389.459\n",
      "\tValid Perplexity: 308.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "\tTrain Perplexity: 317.485\n",
      "\tValid Perplexity: 260.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "\tTrain Perplexity: 284.262\n",
      "\tValid Perplexity: 234.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "\tTrain Perplexity: 264.578\n",
      "\tValid Perplexity: 218.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "\tTrain Perplexity: 251.509\n",
      "\tValid Perplexity: 206.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "\tTrain Perplexity: 242.116\n",
      "\tValid Perplexity: 198.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "\tTrain Perplexity: 235.145\n",
      "\tValid Perplexity: 191.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "\tTrain Perplexity: 229.338\n",
      "\tValid Perplexity: 186.380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain Perplexity: 224.863\n",
      "\tValid Perplexity: 182.146\n",
      "\tFinal train Perplexity: 182.146\n",
      "Lanuage: beng\n",
      "Data: question_text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tTrain Perplexity: 1364.253\n",
      "\tValid Perplexity: 554.291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "\tTrain Perplexity: 554.382\n",
      "\tValid Perplexity: 490.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "\tTrain Perplexity: 520.503\n",
      "\tValid Perplexity: 470.890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "\tTrain Perplexity: 450.435\n",
      "\tValid Perplexity: 352.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "\tTrain Perplexity: 309.572\n",
      "\tValid Perplexity: 248.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "\tTrain Perplexity: 235.858\n",
      "\tValid Perplexity: 199.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "\tTrain Perplexity: 195.050\n",
      "\tValid Perplexity: 166.260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "\tTrain Perplexity: 160.304\n",
      "\tValid Perplexity: 134.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "\tTrain Perplexity: 129.368\n",
      "\tValid Perplexity: 107.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain Perplexity: 104.487\n",
      "\tValid Perplexity: 87.187\n",
      "\tFinal train Perplexity: 87.187\n",
      "Data: document_plaintext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tTrain Perplexity: 1531.547\n",
      "\tValid Perplexity: 928.089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "\tTrain Perplexity: 770.030\n",
      "\tValid Perplexity: 588.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "\tTrain Perplexity: 544.857\n",
      "\tValid Perplexity: 436.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "\tTrain Perplexity: 431.630\n",
      "\tValid Perplexity: 351.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "\tTrain Perplexity: 361.721\n",
      "\tValid Perplexity: 294.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "\tTrain Perplexity: 312.863\n",
      "\tValid Perplexity: 254.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "\tTrain Perplexity: 277.311\n",
      "\tValid Perplexity: 224.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "\tTrain Perplexity: 250.307\n",
      "\tValid Perplexity: 201.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "\tTrain Perplexity: 229.375\n",
      "\tValid Perplexity: 183.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain Perplexity: 212.529\n",
      "\tValid Perplexity: 168.675\n",
      "\tFinal train Perplexity: 168.675\n",
      "Lanuage: indo\n",
      "Data: question_text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tTrain Perplexity: 760.252\n",
      "\tValid Perplexity: 404.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "\tTrain Perplexity: 410.653\n",
      "\tValid Perplexity: 374.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "\tTrain Perplexity: 352.168\n",
      "\tValid Perplexity: 259.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "\tTrain Perplexity: 182.629\n",
      "\tValid Perplexity: 128.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "\tTrain Perplexity: 114.853\n",
      "\tValid Perplexity: 92.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "\tTrain Perplexity: 87.125\n",
      "\tValid Perplexity: 72.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "\tTrain Perplexity: 70.647\n",
      "\tValid Perplexity: 60.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "\tTrain Perplexity: 60.059\n",
      "\tValid Perplexity: 51.940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "\tTrain Perplexity: 52.285\n",
      "\tValid Perplexity: 45.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain Perplexity: 46.154\n",
      "\tValid Perplexity: 40.092\n",
      "\tFinal train Perplexity: 40.092\n",
      "Data: document_plaintext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tTrain Perplexity: 1355.529\n",
      "\tValid Perplexity: 779.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "\tTrain Perplexity: 580.226\n",
      "\tValid Perplexity: 426.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "\tTrain Perplexity: 396.635\n",
      "\tValid Perplexity: 320.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "\tTrain Perplexity: 321.987\n",
      "\tValid Perplexity: 265.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "\tTrain Perplexity: 278.658\n",
      "\tValid Perplexity: 230.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "\tTrain Perplexity: 250.102\n",
      "\tValid Perplexity: 206.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "\tTrain Perplexity: 229.761\n",
      "\tValid Perplexity: 188.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "\tTrain Perplexity: 214.528\n",
      "\tValid Perplexity: 175.430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "\tTrain Perplexity: 202.755\n",
      "\tValid Perplexity: 165.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain Perplexity: 193.284\n",
      "\tValid Perplexity: 156.357\n",
      "\tFinal train Perplexity: 156.357\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "lang = [(bpemb_ar, train_arab, val_arab, 'arab'), \n",
    "        (bpemb_bn, train_beng, val_beng, 'beng'), \n",
    "        (bpemb_id, train_indo, val_indo, 'indo')]\n",
    "\n",
    "# Train and validate all 6 models\n",
    "for vocab, train_df, val_df, ln in lang:\n",
    "    print(f'Lanuage: {ln}')\n",
    "    for doc in ['question_text', 'document_plaintext']:\n",
    "        print(f'Data: {doc}')\n",
    "        \n",
    "        train_data = get_data(train_df[doc], vocab, batch_size)\n",
    "        val_data = get_data(val_df[doc], vocab, batch_size)\n",
    "\n",
    "        model = LSTM(hidden_dim, num_layers, dropout_rate, tie_weights, vocab).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "        # reduce learning rate as we go along \n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3) \n",
    "\n",
    "        if saved:\n",
    "            model.load_state_dict(torch.load('best-val-lstm_lm.pt',  map_location=device))\n",
    "            test_loss = evaluate(model, val_data, criterion, batch_size, seq_len, device)\n",
    "            print(f'Test Perplexity: {math.exp(test_loss):.3f}')\n",
    "        else:\n",
    "            best_valid_loss = float('inf')\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                \n",
    "                train_loss = train(model, train_data, optimizer, criterion, \n",
    "                            batch_size, seq_len, clip, device)\n",
    "                valid_loss = evaluate(model, val_data, criterion, batch_size, \n",
    "                            seq_len, device)\n",
    "                \n",
    "                lr_scheduler.step(valid_loss)\n",
    "\n",
    "                if valid_loss < best_valid_loss:\n",
    "                    best_valid_loss = valid_loss\n",
    "                    name = 'best-val-'+ln+'-'+doc+'.pt'\n",
    "                    torch.save(model.state_dict(), name)\n",
    "\n",
    "                print(f'Epoch: {epoch+1}')\n",
    "                print(f'\\tTrain Perplexity: {math.exp(train_loss):.3f}')\n",
    "                print(f'\\tValid Perplexity: {math.exp(valid_loss):.3f}')\n",
    "            \n",
    "            valid_loss = evaluate(model, train_data, criterion, batch_size, \n",
    "                            seq_len, device)\n",
    "            print(f'\\tFinal train Perplexity: {math.exp(valid_loss):.3f}')\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train and evaluate loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next word generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, device, seed=None):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    model.eval()\n",
    "    tokens = tokenizer(prompt)\n",
    "    indices = [vocab[t] for t in tokens]\n",
    "    batch_size = 1\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(max_seq_len):\n",
    "            src = torch.LongTensor([indices]).to(device)\n",
    "            prediction, hidden = model(src, hidden)\n",
    "            probs = torch.softmax(prediction[:, -1] / temperature, dim=-1)  \n",
    "            prediction = torch.multinomial(probs, num_samples=1).item()    \n",
    "            \n",
    "            while prediction == vocab['<unk>']:\n",
    "                prediction = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            if prediction == vocab['<eos>']:\n",
    "                break\n",
    "\n",
    "            indices.append(prediction)\n",
    "\n",
    "    itos = vocab.get_itos()\n",
    "    tokens = [itos[i] for i in indices]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "prompt = '' # Some example\n",
    "max_seq_len = 30\n",
    "seed = 0\n",
    "\n",
    "temperatures = [0.5, 0.7, 0.75, 0.8, 1.0]\n",
    "for temperature in temperatures:\n",
    "    generation = generate(prompt, max_seq_len, temperature, model, tokenizer, \n",
    "                          vocab, device, seed)\n",
    "    print(str(temperature)+'\\n'+' '.join(generation)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
