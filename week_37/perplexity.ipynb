{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42613b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.7) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/oliver/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import Preprocessor as p\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "gen = pipeline('text-generation', model='gpt2')\n",
    "import csv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from helpMe import get_ppl, convert_to_float, getList, Average\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from customDataset import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414d88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8876a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the copenlu/answerable_tydiqa dataset\n",
    "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
    "\n",
    "train_df = dataset['train'].to_pandas()\n",
    "train_df = train_df[train_df['language'].isin(['indonesian', 'arabic', 'bengali'])]\n",
    "train_df = p.DataFramePreprocessor(train_df).df\n",
    "\n",
    "val_df = dataset['validation'].to_pandas()\n",
    "val_df = val_df[val_df['language'].isin(['indonesian', 'arabic', 'bengali'])]\n",
    "val_df = p.DataFramePreprocessor(val_df).df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9d3b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df\n",
    "data['document_length'] = data['document_plaintext'].str.len()\n",
    "data['is_answerable'] = data['annotations'].apply(lambda x: x.get('answer_start', [-1])[0] != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ffd9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliver/.local/lib/python3.8/site-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': 'Genghis Khan was the founder of Khan'} \n",
      "\n",
      "{'generated_text': 'Genghis Khan was the first to admit'} \n",
      "\n",
      "{'generated_text': 'Genghis Khan was the youngest son of'} \n",
      "\n",
      "original text: Genghis Khan was the king of which clan?\n"
     ]
    }
   ],
   "source": [
    "fst_prompt = train_df.iloc[0]['question_text']\n",
    "from translate import Translator\n",
    "translator_in = Translator(to_lang=\"en\", from_lang = \"bn\")\n",
    "translator_out = Translator(to_lang=\"bn\", from_lang = \"en\")\n",
    "translation = translator_in.translate(fst_prompt).split()\n",
    "text = \" \".join(translation[:4])\n",
    "out = gen(text,num_return_sequences = 3, max_length = len(translation)+1)\n",
    "print(out[0],\"\\n\")\n",
    "print(out[1],\"\\n\")\n",
    "print(out[2],\"\\n\")\n",
    "print(\"original text: \" + \" \".join(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b405fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8ccf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfe0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4001c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19538dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inputs_wiki_text = tokenizer(\"Generative Pretrained Transformer is an opensource artificial intelligence created by OpenAI in February 2019\", return_tensors = \"pt\")\\nloss = model(input_ids = inputs_wiki_text[\"input_ids\"], labels = inputs_wiki_text[\"input_ids\"]).loss\\nppl = torch.exp(loss)\\nprint(ppl)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inputs = tokenizer(data['question_text'][3], return_tensors = \"pt\")\n",
    "#loss = model(input_ids = inputs[\"input_ids\"], labels = inputs[\"input_ids\"]).loss\n",
    "#ppl = torch.exp(loss)\n",
    "#print(ppl)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"inputs_wiki_text = tokenizer(\"Generative Pretrained Transformer is an opensource artificial intelligence created by OpenAI in February 2019\", return_tensors = \"pt\")\n",
    "loss = model(input_ids = inputs_wiki_text[\"input_ids\"], labels = inputs_wiki_text[\"input_ids\"]).loss\n",
    "ppl = torch.exp(loss)\n",
    "print(ppl)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df9476a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bengali = data[data['language'] == 'bengali']\n",
    "arabic = data[data['language'] == 'arabic']\n",
    "indonesian = data[data['language'] == 'indonesian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e15c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e473432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7388d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ben = get_ppl(bengali, \"bengali\")\n",
    "#ara = get_ppl(arabic, \"arabic\")\n",
    "#ind = get_ppl(indonesian, \"indonesian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a82adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_a = pd.read_csv('arabic.csv')  \n",
    "ppl_b = pd.read_csv('bengali.csv')  \n",
    "ppl_i = pd.read_csv('indonesian.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b9dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb39149",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_ara = getList('arabic.csv')[0]\n",
    "ppl_ben = getList('bengali.csv')[0]\n",
    "ppl_ind = getList('indonesian.csv')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a41f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = Average(convert_to_float(ppl_ara))\n",
    "be = Average(convert_to_float(ppl_ben))\n",
    "ind = Average(convert_to_float(ppl_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf2ba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.281176299731527\n",
      "5.924668006843454\n",
      "3924.599611058437\n"
     ]
    }
   ],
   "source": [
    "print(ar)\n",
    "print(be)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85efd703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.Dataset.iloc[index]['document_plaintext']\n",
    "        label = self.Dataset.iloc[index]['is_answerable']\n",
    "        \n",
    "        # Convert the label to 0 if False, 1 if True\n",
    "        label = 1 if label else 0\n",
    "        \n",
    "        return text, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ad9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5574d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 2  # You can adjust this based on your needs\n",
    "\n",
    "# Create an instance of your custom dataset\n",
    "bengali = bengali[['document_plaintext','is_answerable']].iloc[1:]\n",
    "custom_dataset = CustomDataset(bengali)\n",
    "test_dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb56b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ca87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9143756b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5aa5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d64567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1dfe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070a8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b156e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ced25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e96d2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import torch\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "\n",
    "# Encode text and generate embeddings\n",
    "text = bengali.iloc[1]['document_plaintext']\n",
    "\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # You can use mean pooling for sentence embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cbedab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f403037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
