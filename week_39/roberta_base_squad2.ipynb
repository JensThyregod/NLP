{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv9GmOy1Ez1K"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install wandb\n",
        "!pip install accelerate -U\n",
        "!pip install scikit-learn\n",
        "!pip install sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuZKxGQhJBYJ",
        "outputId": "863260cd-5f61-4548-f39d-e6ad658f58a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjensthyregod\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filter: 100%|██████████| 116067/116067 [00:02<00:00, 47050.63 examples/s]\n",
            "Filter: 100%|██████████| 13325/13325 [00:00<00:00, 49515.65 examples/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = tydiqa_dataset[\"train\"].filter(lambda example: example['language'] == 'arabic')\n",
        "val_dataset = tydiqa_dataset[\"validation\"].filter(lambda example: example['language'] == 'arabic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
              "    num_rows: 29598\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
              "    num_rows: 11394\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url'],\n",
              "    num_rows: 4779\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0f1e3407379d41a4ac9479138ae16d2e",
            "f93e662d17dc45548240aff1be2a0438",
            "247ceb5462d8403eb556fc1dbff1d3bd",
            "8a06441817a241a2abf3e32d382cca7a",
            "52a7887c206b4f26bbaca6a72b728657",
            "5adf3dba928744f39c9a9ac5a144ef8c",
            "4b7f0ddb3dd648cda6b57ce70609f110",
            "cf232d4330fe49389f77c22b7447e77e",
            "2bbdd2b9756f456cb10f8362d866f01d",
            "a9292b5973604282986c238f221a68fa",
            "c067095b9bd0435caf82ff384625bdba"
          ]
        },
        "id": "ONbu0yZIEdei",
        "outputId": "ca7fb8e1-6a98-46d7-a61c-2a6f8cda90df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filter: 100%|██████████| 116067/116067 [00:02<00:00, 41896.74 examples/s]\n",
            "Filter: 100%|██████████| 13325/13325 [00:00<00:00, 42783.62 examples/s]\n",
            "Map: 100%|██████████| 477/477 [00:00<00:00, 2228.05 examples/s]\n",
            "Map: 100%|██████████| 22/22 [00:00<00:00, 1412.61 examples/s]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Specify the percentage of the dataset to keep\n",
        "dataset_percentage = 0.1\n",
        "\n",
        "# Set the language you want to focus on\n",
        "language = 'bengali'\n",
        "\n",
        "# Load the dataset\n",
        "tydiqa_dataset = load_dataset('copenlu/answerable_tydiqa')\n",
        "\n",
        "# Filter the dataset for the specified language\n",
        "train_dataset = tydiqa_dataset[\"train\"].filter(lambda example: example['language'] == language)\n",
        "val_dataset = tydiqa_dataset[\"validation\"].filter(lambda example: example['language'] == language)\n",
        "\n",
        "# Sample a subset of the dataset\n",
        "train_dataset = train_dataset.shuffle(seed=42).select(range(int(len(train_dataset) * dataset_percentage)))\n",
        "val_dataset = val_dataset.shuffle(seed=42).select(range(int(len(val_dataset) * dataset_percentage)))\n",
        "\n",
        "# Initialize the tokenizer from the XLM-Roberta model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"deepset/xlm-roberta-base-squad2\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Tokenize the examples\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['question_text'],\n",
        "        examples['document_plaintext'],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "    )\n",
        "\n",
        "    # Extract overflow_to_sample_mapping and remove it from tokenized_inputs\n",
        "    overflow_to_sample_mapping = tokenized_inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    offset_mappings = tokenized_inputs.pop(\"offset_mapping\")\n",
        "\n",
        "    # Initialize new lists for storing outputs\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    answer_texts = []\n",
        "    \n",
        "    \n",
        "    # Iterate through the annotations and calculate start and end token positions\n",
        "    for i, offsets in enumerate(offset_mappings):\n",
        "        parent_id = overflow_to_sample_mapping[i]\n",
        "        answer_start = examples['annotations'][parent_id]['answer_start'][0]\n",
        "        answer_text = examples['annotations'][parent_id]['answer_text'][0]\n",
        "        answer_end = answer_start + len(answer_text)\n",
        "\n",
        "        # Find the start and end token index for the answer\n",
        "        start_token_idx = end_token_idx = 0\n",
        "        for idx, (start, end) in enumerate(offsets):\n",
        "            if start <= answer_start < end:\n",
        "                start_token_idx = idx\n",
        "            if start < answer_end <= end:\n",
        "                end_token_idx = idx\n",
        "                break\n",
        "\n",
        "        start_positions.append(start_token_idx)\n",
        "        end_positions.append(end_token_idx)\n",
        "        answer_texts.append(answer_text)\n",
        "\n",
        "    \n",
        "    # Return the new lists as a dictionary\n",
        "    return {\n",
        "        'input_ids': tokenized_inputs['input_ids'],\n",
        "        'attention_mask': tokenized_inputs['attention_mask'],\n",
        "        'start_positions': start_positions,\n",
        "        'end_positions': end_positions,\n",
        "        'answer_texts': answer_texts\n",
        "    }\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\n",
        "val_dataset = val_dataset.map(preprocess_function, batched=True, remove_columns=val_dataset.column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4779"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset['question_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bfb1889ff47d4cfcb168eeba64a68c6a",
            "76a45369890c4a67ab712f3967977026",
            "495f95c2ec054056b860e0398b4b186d",
            "946afb8cdc99499bbf168179f8d27017",
            "49ef5156df174a948b30f45190ccaac2",
            "c830a2bdbadf46bdaafd71b3dae832d4",
            "6671f065b7604975a0c5c7e4d34326c1",
            "d4956ee400f5479ea4a74fe1fffb40e6"
          ]
        },
        "id": "bcOwjXrZEdek",
        "outputId": "d50a2976-9253-42ab-b5e6-9dd75b75e774"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "wandb version 0.15.12 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.17"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/jensthyregod/Desktop/KU/7. Semester/NLP/week_39/wandb/run-20231022_144208-26ug75b2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jensthyregod/NLP_KU_QA/runs/26ug75b2\" target=\"_blank\">english_v2</a></strong> to <a href=\"https://wandb.ai/jensthyregod/NLP_KU_QA\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /Users/jensthyregod/.cache/huggingface/hub/models--deepset--xlm-roberta-base-squad2/snapshots/a17f72834366c08e1442ba44b483983d86d659bf/config.json\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"deepset/xlm-roberta-base-squad2\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.5,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.5,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"language\": \"english\",\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"name\": \"XLMRoberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /Users/jensthyregod/.cache/huggingface/hub/models--deepset--xlm-roberta-base-squad2/snapshots/a17f72834366c08e1442ba44b483983d86d659bf/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing XLMRobertaForQuestionAnswering.\n",
            "\n",
            "All the weights of XLMRobertaForQuestionAnswering were initialized from the model checkpoint at deepset/xlm-roberta-base-squad2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForQuestionAnswering for predictions without further training.\n",
            "PyTorch: setting up devices\n",
            "The following columns in the training set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: answer_texts. If answer_texts are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n",
            "/Users/jensthyregod/mambaforge/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 750\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 2\n",
            "  Total optimization steps = 235\n",
            "  Number of trainable parameters = 277454594\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.nn.functional as F\n",
        "from transformers import XLMRobertaForQuestionAnswering, XLMRobertaTokenizer, TrainingArguments, Trainer, XLMRobertaConfig, EvalPrediction\n",
        "import wandb\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = np.argmax(p.predictions, axis=2).flatten()\n",
        "    labels = p.label_ids.flatten()\n",
        "\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    exact_match = np.mean(labels == preds)\n",
        "    euclidean_distance = euclidean(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'f1': f1,\n",
        "        'exact_match': exact_match,\n",
        "        'euclidean_distance': euclidean_distance\n",
        "    }\n",
        "\n",
        "# Ensure TOKENIZERS_PARALLELISM is set to false to avoid warnings\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
        "\n",
        "# Define the language and version number\n",
        "version = 2\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project='NLP_KU_QA', name=f'{language}_v{version}')\n",
        "\n",
        "# Load the model configuration and set dropout\n",
        "config = XLMRobertaConfig.from_pretrained(\"deepset/xlm-roberta-base-squad2\", hidden_dropout_prob=0.5, attention_probs_dropout_prob=0.5)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(\"deepset/xlm-roberta-base-squad2\")\n",
        "\n",
        "# Load the model and send it to the GPU (if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = XLMRobertaForQuestionAnswering.from_pretrained(\"deepset/xlm-roberta-base-squad2\", config=config).to(device)\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=5,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=20,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    output_dir='./results',\n",
        "    push_to_hub=False,\n",
        "    logging_first_step=True,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"wandb\",\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,  # Make sure train_dataset is defined\n",
        "    eval_dataset=val_dataset,  # Make sure val_dataset is defined\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=default_data_collator\n",
        ")\n",
        "\n",
        "try:\n",
        "    # Train and evaluate the model\n",
        "    trainer.train()\n",
        "    trainer.evaluate()\n",
        "finally:\n",
        "    # Save the model and tokenizer\n",
        "    model.save_pretrained('./my_roberta_qa_model')\n",
        "    tokenizer.save_pretrained('./my_roberta_qa_model')  # Make sure tokenizer is defined\n",
        "    # Ensure wandb session is ended properly\n",
        "    wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcidkj_SEdel",
        "outputId": "9fb8d281-2c4c-4533-abed-a44d46863bd7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/zr/c8f6vstn63316p5z6pj3jlp00000gn/T/ipykernel_28482/4046092757.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "model = RobertaForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")\n",
        "\n",
        "# Define training arguments\n",
        "args = TrainingArguments(\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    save_steps=1000,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    learning_rate=3e-5,\n",
        "    num_train_epochs=2,\n",
        "    output_dir=\"./results\",\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()\n",
        "\n",
        "# Save model\n",
        "model.save_pretrained(\"./my_finetuned_model\")\n",
        "tokenizer.save_pretrained(\"./my_finetuned_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKMu0UyfEdel"
      },
      "outputs": [],
      "source": [
        "for row in train_df.iterrows():\n",
        "    answer_start = row[1]['annotations']['answer_start'][0]\n",
        "\n",
        "    answer_text = row[1]['annotations']['answer_text'][0]\n",
        "\n",
        "    ## add the new answer_start column\n",
        "    train_df.at[row[0], 'answer_start'] = answer_start\n",
        "\n",
        "    ## add the new answer_text column\n",
        "    train_df.at[row[0], 'answer_text'] = answer_text\n",
        "\n",
        "## cast answer_start to int\n",
        "train_df['answer_start'] = train_df['answer_start'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tfqmll-lEdel"
      },
      "outputs": [],
      "source": [
        "for row in val_df.iterrows():\n",
        "    answer_start = row[1]['annotations']['answer_start'][0]\n",
        "\n",
        "    answer_text = row[1]['annotations']['answer_text'][0]\n",
        "\n",
        "    ## add the new answer_start column\n",
        "    val_df.at[row[0], 'answer_start'] = answer_start\n",
        "\n",
        "    ## add the new answer_text column\n",
        "    val_df.at[row[0], 'answer_text'] = answer_text\n",
        "\n",
        "## cast answer_start to int\n",
        "val_df['answer_start'] = val_df['answer_start'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pfeN-jREdel"
      },
      "outputs": [],
      "source": [
        "train_df[:4000].to_csv('train.csv', index=False)\n",
        "val_df[:1000].to_csv('val.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUOIBBMuEdel",
        "outputId": "b46fbd7b-dfd8-4b2c-e0a8-371a82399c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Siapa bapak Teknik industri?\n",
            "Awal mula Teknik Industri dapat ditelusuri dari beberapa sumber berbeda. Frederick Winslow Taylor sering ditetapkan sebagai Bapak Teknik Industri meskipun seluruh gagasannya tidak asli. Beberapa risalah terdahulu mungkin telah memengaruhi perkembangan Teknik Industri seperti risalah The Wealth of Nations karya Adam Smith, dipublikasikan tahun 1776; Essay on Population karya Thomas Malthus dipublikasikan tahun 1798; Principles of Political Economy and Taxation karya David Ricardo, dipublikasikan tahun 1817; dan Principles of Political Economy karya John Stuart Mill, dipublikasikan tahun 1848. Seluruh hasil karya ini mengilhami penjelasan paham Liberal Klasik mengenai kesuksesan dan keterbatas dari Revolusi Industri. Adam Smith adalah ekonom yang terkenal pada zamannya. \"Economic Science\" adalah frasa untuk menggambarkan bidang ini di Inggris sebelum industrialisasi America muncul .\n",
            "{'answer_start': array([73]), 'answer_text': array(['Frederick Winslow Taylor'], dtype=object)}\n"
          ]
        }
      ],
      "source": [
        "print(val_df.iloc[10]['question_text'])\n",
        "print(val_df.iloc[10]['document_plaintext'])\n",
        "print(val_df.iloc[10]['annotations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls_mNh8xEdem"
      },
      "outputs": [],
      "source": [
        "train_df.to_csv('train.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f1e3407379d41a4ac9479138ae16d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f93e662d17dc45548240aff1be2a0438",
              "IPY_MODEL_247ceb5462d8403eb556fc1dbff1d3bd",
              "IPY_MODEL_8a06441817a241a2abf3e32d382cca7a"
            ],
            "layout": "IPY_MODEL_52a7887c206b4f26bbaca6a72b728657"
          }
        },
        "247ceb5462d8403eb556fc1dbff1d3bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf232d4330fe49389f77c22b7447e77e",
            "max": 4779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bbdd2b9756f456cb10f8362d866f01d",
            "value": 4000
          }
        },
        "2bbdd2b9756f456cb10f8362d866f01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "495f95c2ec054056b860e0398b4b186d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6671f065b7604975a0c5c7e4d34326c1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4956ee400f5479ea4a74fe1fffb40e6",
            "value": 1
          }
        },
        "49ef5156df174a948b30f45190ccaac2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b7f0ddb3dd648cda6b57ce70609f110": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52a7887c206b4f26bbaca6a72b728657": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5adf3dba928744f39c9a9ac5a144ef8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6671f065b7604975a0c5c7e4d34326c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a45369890c4a67ab712f3967977026": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49ef5156df174a948b30f45190ccaac2",
            "placeholder": "​",
            "style": "IPY_MODEL_c830a2bdbadf46bdaafd71b3dae832d4",
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "8a06441817a241a2abf3e32d382cca7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9292b5973604282986c238f221a68fa",
            "placeholder": "​",
            "style": "IPY_MODEL_c067095b9bd0435caf82ff384625bdba",
            "value": " 4000/4779 [00:15&lt;00:02, 291.45 examples/s]"
          }
        },
        "946afb8cdc99499bbf168179f8d27017": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9292b5973604282986c238f221a68fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfb1889ff47d4cfcb168eeba64a68c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76a45369890c4a67ab712f3967977026",
              "IPY_MODEL_495f95c2ec054056b860e0398b4b186d"
            ],
            "layout": "IPY_MODEL_946afb8cdc99499bbf168179f8d27017"
          }
        },
        "c067095b9bd0435caf82ff384625bdba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c830a2bdbadf46bdaafd71b3dae832d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf232d4330fe49389f77c22b7447e77e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4956ee400f5479ea4a74fe1fffb40e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f93e662d17dc45548240aff1be2a0438": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5adf3dba928744f39c9a9ac5a144ef8c",
            "placeholder": "​",
            "style": "IPY_MODEL_4b7f0ddb3dd648cda6b57ce70609f110",
            "value": "Map:  84%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
